---
title: Language model
---

import { Aside, Tabs, TabItem, Code } from "@astrojs/starlight/components";
import jsGetModelCode from "../../../../../sdk-js/examples/get-model.ts?raw";
import rustGetModelCode from "../../../../../sdk-rust/examples/common/mod.rs?raw";
import goGetModelCode from "../../../../../sdk-go/examples/model.go?raw";

A language model instance satisfies the `LanguageModel` interface, which includes the following:

- `provider`: The LLM provider name.
- `model_id`: The model identifier.
- `metadata`: Metadata about the model, such as pricing information or capabilities.
- `generate(LanguageModelInput) -> ModelResponse`: Generate a non-streaming response from the model.
- `stream(LanguageModelInput) -> AsyncIterable<PartialModelResponse>`: Generate a streaming response from the model.

All models in the library implement the LanguageModel interface and can be used interchangeably.

<Tabs>
  <TabItem label="TypeScript">
    <Code code={jsGetModelCode} lang="typescript" title="get-model.ts" />
  </TabItem>
  <TabItem label="Rust">
    <Code code={rustGetModelCode} lang="rust" title="mod.rs" />
  </TabItem>
  <TabItem label="Go">
    <Code code={goGetModelCode} lang="go" title="model.go" />
  </TabItem>
</Tabs>

## Language Model Input

`LanguageModelInput` is a unified format to represent the input for generating responses from the language model, applicable to both non-streaming and streaming requests. The library converts these inputs into corresponding properties for each LLM provider, if applicable. This allows specifying:

- The conversation history, which includes `UserMessage`, `AssistantMessage`, and `ToolMessage`.
- Sampling parameters: `max_tokens`, `temperature`, `top_p`, `top_k`, `presence_penalty`, `frequency_penalty`, and `seed`.
- Tool definitions and tool selection.
- The response format to enforce the model to return structured objects instead of plain text.

```typescript
export interface LanguageModelInput {
  /**
   * A system prompt is a way of providing context and instructions to the model
   */
  system_prompt?: string;
  /**
   * A list of messages comprising the conversation so far.
   */
  messages: Message[];
  /**
   * Definitions of tools that the model may use.
   */
  tools?: Tool[];
  tool_choice?: ToolChoiceOption;
  response_format?: ResponseFormatOption;
  /**
   * The maximum number of tokens that can be generated in the chat completion.
   */
  max_tokens?: number;
  /**
   * Amount of randomness injected into the response. Ranges from 0.0 to 1.0
   */
  temperature?: number;
  /**
   * An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. Ranges from 0.0 to 1.0
   */
  top_p?: number;
  /**
   * Only sample from the top K options for each subsequent token. Used to remove 'long tail' low probability responses. Ranges from 0.0 to 1.0
   */
  top_k?: number;
  /**
   * Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.
   */
  presence_penalty?: number;
  /**
   * Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.
   */
  frequency_penalty?: number;
  /**
   * The seed (integer), if set and supported by the model, to enable deterministic results.
   */
  seed?: number;
  /**
   * The modalities that the model should support.
   */
  modalities?: Modality[];
  /**
   * A set of key/value pairs that store additional information about the request. This is forwarded to the model provider if supported.
   */
  metadata?: Record<string, string>;
  /**
   * Extra options that the model may support.
   */
  extra?: Record<string, unknown>;
}
```

## Message

`Message`s are primitives that make up the conversation history, and `Part`s are the building blocks of each message. The library converts them into a format suitable for the underlying LLM provider and maps those from different providers to the unified format.

Three message types are defined in the SDK: `UserMessage`, `AssistantMessage`, and `ToolMessage`.

```typescript
export type Message = UserMessage | AssistantMessage | ToolMessage;

/**
 * Represents a message sent by the user.
 */
export interface UserMessage {
  role: "user";
  content: Part[];
}
/**
 * Represents a message generated by the model.
 */
export interface AssistantMessage {
  role: "assistant";
  content: Part[];
}

/**
 * Represents tool result in the message history.
 * Only ToolResultPart should be included in the content.
 */
export interface ToolMessage {
  role: "tool";
  content: Part[];
}
```

## Part

The following `Part` types are implemented in the SDK: `TextPart`, `ImagePart`, `AudioPart`, `SourcePart` (for citation), `ToolCallPart`, and `ToolResultPart`.

```typescript
/**
 * A part of the message.
 */
export type Part =
  | TextPart
  | ImagePart
  | AudioPart
  | SourcePart
  | ToolCallPart
  | ToolResultPart;
```

### Text Part

```typescript
/**
 * A part of the message that contains text.
 */
export interface TextPart {
  type: "text";
  text: string;
  citations?: Citation[];
}
```

### Image Part

```typescript
/**
 * A part of the message that contains an image.
 */
export interface ImagePart {
  type: "image";
  /**
   * The MIME type of the image. E.g. "image/jpeg", "image/png".
   */
  mime_type: string;
  /**
   * The base64-encoded image data.
   */
  image_data: string;
  /**
   * The width of the image in pixels.
   */
  width?: number;
  /**
   * The height of the image in pixels.
   */
  height?: number;
}
```

### Audio Part

```typescript
/**
 * A part of the message that contains an audio.
 */
export interface AudioPart {
  type: "audio";
  /**
   * The base64-encoded audio data.
   */
  audio_data: string;
  format: AudioFormat;
  /**
   * The sample rate of the audio. E.g. 44100, 48000.
   */
  sample_rate?: number;
  /**
   * The number of channels of the audio. E.g. 1, 2.
   */
  channels?: number;
  /**
   * The transcript of the audio.
   */
  transcript?: string;
  /**
   * Audio ID, if applicable.
   */
  audio_id?: string;
}
```

### Source Part

```typescript
/**
 * A part of the message that contains a source with structured content.
 * It will be used for citation for supported models.
 */
export interface SourcePart {
  type: "source";
  /**
   * The title of the document.
   */
  title: string;
  /**
   * The content of the document.
   */
  content: Part[];
}
```

### Tool Call Part

<Aside>
  Tool calls are implemented as a `Part` instead of being a property of the
  `AssistantMessage`.
</Aside>

```typescript
/**
 * A part of the message that represents a call to a tool the model wants to use.
 */
export interface ToolCallPart {
  type: "tool-call";
  /**
   * The ID of the tool call, used to match the tool result with the tool call.
   */
  tool_call_id: string;
  /**
   * The name of the tool to call.
   */
  tool_name: string;
  /**
   * The arguments to pass to the tool.
   */
  args: Record<string, unknown>;
}
```

### Tool Result Part

<Aside>
  The `ToolResultPart` content is an array of `Part` instead of a string or an
  object. This enables non-text results to be returned for LLM providers that
  support them (e.g., Anthropic Function Calling supports images in tool
  results).
</Aside>

```typescript
/**
 * A part of the message that represents the result of a tool call.
 */
export interface ToolResultPart {
  type: "tool-result";
  /**
   * The ID of the tool call from previous assistant message.
   */
  tool_call_id: string;
  /**
   * The name of the tool that was called.
   */
  tool_name: string;
  /**
   * The content of the tool result.
   */
  content: Part[];
  /**
   * Marks the tool result as an error.
   */
  is_error?: boolean;
}
```

## Model Response

The response from the language model is represented as a `ModelResponse` that includes:

- `content`: An array of `Part` that represents the generated content, which usually comes from the `AssistantMessage`.
- `usage`: Token usage information, if available.
- `cost`: The estimated cost of the request, if the model's pricing information is provided.

```typescript
/**
 * Represents the response generated by the model.
 */
export interface ModelResponse {
  content: Part[];
  usage?: ModelUsage;
  /**
   * The cost of the response.
   */
  cost?: number;
}

/**
 * Represents the token usage of the model.
 */
export interface ModelUsage {
  input_tokens: number;
  output_tokens: number;
  input_tokens_details?: ModelTokensDetails;
  output_tokens_details?: ModelTokensDetails;
}

/**
 * Represents the token usage of the model.
 */
export interface ModelTokensDetails {
  text_tokens?: number;
  cached_text_tokens?: number;
  audio_tokens?: number;
  cached_audio_tokens?: number;
  image_tokens?: number;
  cached_image_tokens?: number;
}
```

For streaming calls, the response is represented as a series of `PartialModelResponse` objects that include:

- `delta`: A `PartDelta` and its index in the eventual `content` array.
- `usage`: Token usage information, if available.

```typescript
/**
 * Represents a delta update in a message's content, enabling partial streaming updates in LLM responses.
 */
export interface ContentDelta {
  index: number;
  part: PartDelta;
}

/**
 * Represents a partial response from the language model, useful for streaming output via async generator.
 */
export interface PartialModelResponse {
  delta?: ContentDelta;
  usage?: ModelUsage;
}
```

All SDKs provide the `StreamAccumulator` utility to help build the final `ModelResponse` from a stream of `PartialModelResponse`.
