---
title: Agent execution
---

import { Aside, Code, TabItem, Tabs } from "@astrojs/starlight/components";
import {
  extractGoAgentTypes,
  extractRustAgentTypes,
  extractTypescriptAgentTypes,
} from "../../../utils/extract-types.ts";

## Agent Request

An agent run is initiated by calling the `run` method with an `AgentRequest`, which includes the following:

- `input`: The list of input `AgentItem` for the agent, such as `Message`s.
- `context`: A user-provided value that can be accessed in instructions and tools.

<Tabs>
  <TabItem label="TypeScript">
    <Code
      code={extractTypescriptAgentTypes([
        "AgentRequest",
        "AgentItem",
      ])}
      lang="typescript"
      title="types.ts"
    />
  </TabItem>
  <TabItem label="Rust">
    <Code
      code={extractRustAgentTypes([
        "AgentRequest",
        "AgentItem",
      ])}
      lang="rust"
      title="types.rs"
    />
  </TabItem>
  <TabItem label="Go">
    <Code
      code={extractGoAgentTypes([
        "AgentRequest",
        "AgentItem",
      ])}
      lang="go"
      title="types.go"
    />
  </TabItem>
</Tabs>

<Aside>
  Each agent run is stateless, so it is recommended to implement a strategy to
  persist the conversation history if needed.
</Aside>

Each run will continuously generate LLM completions, parse responses to check for tool calls, execute any tools, and feed the tool results back to the model until one of the following conditions is met:

- The model generates a final response (i.e., no tool call).
- The maximum number of turns is reached.

## Agent Response

`AgentResponse` includes the final response with the following properties:

- `output`: A list of output `AgentItem`, such as `ToolMessage` and `AssistantMessage`, that were generated during the run. This can be used to append to the `input` of the next run.
- `content`: The final content generated by the agent, which is usually the content of the last `AssistantMessage`.
- `model_calls`: A list of `ModelCallInfo` describing the LLM calls including their usage and cost.

<Tabs>
  <TabItem label="TypeScript">
    <Code
      code={extractTypescriptAgentTypes(["AgentResponse", "ModelCallInfo"])}
      lang="typescript"
      title="types.ts"
    />
  </TabItem>
  <TabItem label="Rust">
    <Code
      code={extractRustAgentTypes(["AgentResponse", "ModelCallInfo"])}
      lang="rust"
      title="types.rs"
    />
  </TabItem>
  <TabItem label="Go">
    <Code
      code={extractGoAgentTypes(["AgentResponse", "ModelCallInfo"])}
      lang="go"
      title="types.go"
    />
  </TabItem>
</Tabs>

The library also provides a streaming interface, similar to streaming LLM completions, to stream the agent run progress, including part deltas (e.g., text deltas, audio deltas) and intermediate tool calls. Each event can either be:

- `AgentStreamEventPartial`: Contains the `PartialModelResponse` as generated by the LLM SDK, which includes part deltas.
- `AgentStreamEventMessage`: Contains a full `Message` (e.g., `ToolMessage` or `AssistantMessage`) that was generated during the run.
- `AgentStreamEventResponse`: The final response of the agent run, which includes the `AgentResponse`.

<Tabs>
  <TabItem label="TypeScript">
    <Code
      code={extractTypescriptAgentTypes([
        "AgentStreamEvent",
        "AgentStreamEventPartial",
        "AgentStreamEventMessage",
        "AgentStreamEventResponse",
      ])}
      lang="typescript"
      title="types.ts"
    />
  </TabItem>
  <TabItem label="Rust">
    <Code
      code={extractRustAgentTypes([
        "AgentStreamEvent",
        "AgentStreamEventPartial",
        "AgentStreamEventMessage",
        "AgentStreamEventResponse",
      ])}
      lang="rust"
      title="types.rs"
    />
  </TabItem>
  <TabItem label="Go">
    <Code
      code={extractGoAgentTypes([
        "AgentStreamEvent",
        "AgentStreamEventPartial",
        "AgentStreamEventMessage",
        "AgentStreamEventResponse",
      ])}
      lang="go"
      title="types.go"
    />
  </TabItem>
</Tabs>

