---
title: Overview
---

import { Code, TabItem, Tabs } from "@astrojs/starlight/components";
import goAgentCode from "../../../../../agent-go/examples/agent/main.go?raw";
import jsAgentCode from "../../../../../agent-js/examples/agent.ts?raw";
import rustAgentCode from "../../../../../agent-rust/examples/agent.rs?raw";

Agents enable the development of LLM AI applications that can generate responses and execute tasks autonomously. Agents utilize the LLM SDK to interact with different language models and allow definitions of instructions, tools, and other language model parameters.

We provide Agent implementations in the following programming languages:

- [JavaScript](https://github.com/hoangvvo/llm-sdk/tree/main/agent-js)
- [Rust](https://github.com/hoangvvo/llm-sdk/tree/main/agent-rust)
- [Go](https://github.com/hoangvvo/llm-sdk/tree/main/agent-go)

Below is an example of how to implement an agent in each language:

<Tabs>
  <TabItem label="TypeScript">
    <Code code={jsAgentCode} lang="typescript" title="agent.ts" />
  </TabItem>
  <TabItem label="Rust">
    <Code code={rustAgentCode} lang="rust" title="agent.rs" />
  </TabItem>
  <TabItem label="Go">
    <Code code={goAgentCode} lang="go" title="main.go" />
  </TabItem>
</Tabs>

## Agent Patterns

This agent **library** (not *framework*) is designed for transparency and control.
Unlike many “agentic” frameworks, it ships with no hidden prompt templates or secret parsing rules, and that’s on purpose:

- Nothing hidden – What you write is what runs. No secret prompts or “special sauce” behind the scenes, so your instructions aren’t quietly overridden.
- Works in any settings – Many frameworks bake in English-only prompts. Here, the model sees only your words, in whichever language or format.
- Easy to tweak – Change prompts, parsing, or flow without fighting built-in defaults.
- Less to debug – Fewer layers mean you can trace exactly where things break.
- No complex abstraction – Don't waste time learning new concepts or APIs (e.g., “chains”, “graphs”, syntax with special meanings, etc.). Just plain functions and data structures.

LLM in the past was not as powerful as today, so frameworks had to do a lot of heavy lifting to get decent results.
But with modern LLMs, much of that complexity is no longer necessary.

Because we keep the core minimal (**only 500 LOC!**) and do not want to introduce such hidden magic, the library doesn’t bundle heavy agent patterns like hand-off, memory, or planners.
Instead, the `examples/` folder shows clean, working references you can copy or adapt to see that it can still be used to build complex use cases.

This philosophy is inspired by this [blog post](https://hamel.dev/blog/posts/prompt/).