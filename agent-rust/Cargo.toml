[package]
description = "The agent library to build LLM applications that work with any LLM providers."
edition = "2021"
homepage = "https://llm-sdk.hoangvvo.com/"
include = [
  "src/**/*",
  "Cargo.toml",
  "README.md",
  "LICENSE",
  "examples/**/*",
  "tests/**/*",
]
keywords = ["llm", "language-model", "agent", "ai", "openai"]
license = "MIT"
name = "llm-agent"
readme = "README.md"
repository = "https://github.com/hoangvvo/llm-sdk"
version = "0.2.0"

[lib]
name = "llm_agent"

[lints.clippy]
missing_errors_doc = "allow"
pedantic = "warn"
use_self = "warn"

[dependencies]
async-stream = "0.3.6"
base64 = "0.22"
futures = "0.3"
llm-sdk-rs = { version = "0.2", path = "../sdk-rust" }
opentelemetry = "0.30"
rmcp = { version = "0.7", features = [
  "client",
  "transport-child-process",
  "transport-streamable-http-client-reqwest",
  "transport-streamable-http-server",
] }
serde = { version = "1", features = ["derive"] }
serde_json = "1"
thiserror = "2"
tokio = { version = "1", features = ["macros", "rt", "process"] }
tracing = "0.1"
tracing-futures = { version = "0.2", features = ["std", "futures-03"] }
tracing-opentelemetry = "0.31"

[dev-dependencies]
axum = "0.8.1"
chrono = "0.4"
dotenvy = { version = "0.15.7" }
opentelemetry-otlp = { version = "0.30", features = [
  "http-proto",
  "trace",
  "reqwest-client",
] }
opentelemetry_sdk = { version = "0.30", features = ["rt-tokio", "trace"] }
rand = { version = "0.8" }
reqwest = { version = "0.12.9", features = ["json"] }
schemars = "1.0.4"
similar = "2"
tokio = { version = "1.42.0", features = ["full"] }
tower = "0.5.1"
tower-http = { version = "0.6.2", features = ["cors"] }
tracing-subscriber = { version = "0.3", features = ["env-filter"] }
urlencoding = "2.1.3"
