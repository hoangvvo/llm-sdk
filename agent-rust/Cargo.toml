[package]
description = "Agents enable the development of agentic AI applications that can generate responses and execute tasks autonomously. Agents utilize the LLM SDK to interact with different language models and allow definitions of instructions, tools, and other language model parameters."
edition = "2021"
homepage = "https://llm-sdk.hoangvvo.com/"
keywords = [
  "llm",
  "language model",
  "agent",
  "ai",
  "openai",
  "anthropic",
  "cohere",
  "mistral",
]
license = "MIT"
name = "llm-agent"
readme = "README.md"
repository = "https://github.com/hoangvvo/llm-sdk"
version = "0.1.0"

[lib]
name = "llm_agent"

[lints.clippy]
missing_errors_doc = "allow"
pedantic = "warn"
use_self = "warn"

[dependencies]
async-stream = "0.3.6"
async-trait = "0.1.86"
base64 = "0.22.1"
futures = "0.3.31"
llm-sdk = { version = "0.1.0", path = "../sdk-rust" }
opentelemetry = "0.30"
rmcp = { version = "0.7.0", features = [
  "client",
  "transport-child-process",
  "transport-streamable-http-client-reqwest",
  "transport-streamable-http-server",
] }
serde = { version = "1.0.217", features = ["derive"] }
serde_json = "1.0.134"
thiserror = "2.0.11"
tokio = { version = "1.42.0", features = ["macros", "rt", "process"] }
tracing = "0.1"
tracing-futures = { version = "0.2", features = ["std", "futures-03"] }
tracing-opentelemetry = "0.31"

[dev-dependencies]
axum = "0.8.1"
chrono = "0.4"
dotenvy = { version = "0.15.7" }
opentelemetry-otlp = { version = "0.30", features = [
  "http-proto",
  "trace",
  "reqwest-client",
] }
opentelemetry_sdk = { version = "0.30", features = ["rt-tokio", "trace"] }
rand = { version = "0.8" }
reqwest = { version = "0.12.9", features = ["json"] }
schemars = "1.0.4"
similar = "2"
tokio = { version = "1.42.0", features = ["full"] }
tower = "0.5.1"
tower-http = { version = "0.6.2", features = ["cors"] }
tracing-subscriber = { version = "0.3", features = ["env-filter"] }
urlencoding = "2.1.3"
